{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#                                                                   #\n",
    "# /dataframe_utilities.py                                           #\n",
    "#                                                                   #\n",
    "# Copyright 2013, Monash University                                 #\n",
    "#                                                                   #\n",
    "# This file is part of the program lyse, in the labscript suite     #\n",
    "# (see http://labscriptsuite.org), and is licensed under the        #\n",
    "# Simplified BSD License. See the license.txt file in the root of   #\n",
    "# the project for the full license.                                 #\n",
    "#                                                                   #\n",
    "#####################################################################\n",
    "import h5py\n",
    "import pandas\n",
    "# import tzlocal\n",
    "\n",
    "# import labscript_utils.h5_lock # Not used \n",
    "\n",
    "# import runmanager\n",
    "def get_shot_globals(filepath):\n",
    "    \"\"\"Returns the evaluated globals for a shot, for use by labscript or lyse.\n",
    "    Simple dictionary access as in dict(h5py.File(filepath).attrs) would be fine\n",
    "    except we want to apply some hacks, so it's best to do that in one place.\"\"\"\n",
    "    params = {}\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        for name, value in f['globals'].attrs.items():\n",
    "            # Convert numpy bools to normal bools:\n",
    "            if isinstance(value, np.bool_):\n",
    "                value = bool(value)\n",
    "            # Convert null HDF references to None:\n",
    "            if isinstance(value, h5py.Reference) and not value:\n",
    "                value = None\n",
    "            # Convert numpy strings to Python ones.\n",
    "            # DEPRECATED, for backward compat with old files.\n",
    "            if isinstance(value, np.str_):\n",
    "                value = str(value)\n",
    "            if isinstance(value, bytes):\n",
    "                value = value.decode()\n",
    "            params[name] = value\n",
    "    return params\n",
    "\n",
    "# from labscript_utils.connections import _ensure_str\n",
    "def _ensure_str(s):\n",
    "    \"\"\"convert bytestrings and numpy strings to python strings\"\"\"\n",
    "    return s.decode() if isinstance(s, bytes) else str(s)\n",
    "\n",
    "# from labscript_utils.properties import get_attributes\n",
    "JSON_IDENTIFIER = 'Content-Type: application/json '\n",
    "BASE64_IDENTIFIER = 'Content-Transfer-Encoding: base64 '\n",
    "import json\n",
    "from collections.abc import Iterable, Mapping\n",
    "from base64 import b64encode, b64decode\n",
    "def get_attributes(group):\n",
    "    \"\"\"Return attributes of a HDF5 group as a dict, deserialising any that have been\n",
    "    encoded as JSON\"\"\"\n",
    "    return {k: deserialise(v) if is_json(v) else v for k, v in group.attrs.items()}\n",
    "def deserialise(value):\n",
    "    assert is_json(value)\n",
    "    return _decode_bytestrings(json.loads(value[len(JSON_IDENTIFIER):]))\n",
    "def is_json(value):\n",
    "    if isinstance(value, bytes):\n",
    "        return value[:len(JSON_IDENTIFIER)] == JSON_IDENTIFIER.encode('utf8')\n",
    "    elif isinstance(value, str):\n",
    "        return value.startswith(JSON_IDENTIFIER)\n",
    "    return False\n",
    "def _decode_bytestrings(o):\n",
    "    \"\"\"Decode all base64-encoded values (not keys) to bytestrings\"\"\"\n",
    "    if isinstance(o, Mapping):\n",
    "        return {key: _decode_bytestrings(value) for key, value in o.items()}\n",
    "    elif isinstance(o, Iterable) and not isinstance(o, (str, bytes)):\n",
    "        return list([_decode_bytestrings(value) for value in o])\n",
    "    elif isinstance(o, str) and o.startswith(BASE64_IDENTIFIER):\n",
    "        return b64decode(o[len(BASE64_IDENTIFIER):])\n",
    "    else:\n",
    "        return o\n",
    "\n",
    "# import labscript_utils.shared_drive # Using path_to_agnostic\n",
    "import os.path\n",
    "def path_to_agnostic(path):\n",
    "    path = os.path.abspath(path)\n",
    "    if path.startswith(prefix):\n",
    "        path = path.split(prefix, 1)[1]\n",
    "        path = 'Z:\\\\' + path\n",
    "        path = path.replace(os.path.sep, '\\\\')\n",
    "    return path\n",
    "\n",
    "def asdatetime(timestr):\n",
    "    if isinstance(timestr, bytes):\n",
    "        timestr = timestr.decode('utf-8')\n",
    "    tz = tzlocal.get_localzone().zone\n",
    "    return pandas.Timestamp(timestr, tz=tz)\n",
    "\n",
    "def get_nested_dict_from_shot(filepath):\n",
    "    row = get_shot_globals(filepath)\n",
    "    with h5py.File(filepath,'r') as h5_file:\n",
    "        if 'results' in h5_file:\n",
    "            for groupname in h5_file['results']:\n",
    "                resultsgroup = h5_file['results'][groupname]\n",
    "                row[groupname] = get_attributes(resultsgroup)\n",
    "        if 'images' in h5_file:\n",
    "            for orientation in h5_file['images'].keys():\n",
    "                if isinstance(h5_file['images'][orientation], h5py.Group):\n",
    "                    row[orientation] = get_attributes(h5_file['images'][orientation])\n",
    "                    for label in h5_file['images'][orientation]:\n",
    "                        row[orientation][label] = {}\n",
    "                        group = h5_file['images'][orientation][label]\n",
    "                        for image in group:\n",
    "                            row[orientation][label][image] = {}\n",
    "                            for key, val in get_attributes(group[image]).items():\n",
    "                                if not isinstance(val, h5py.Reference):\n",
    "                                    row[orientation][label][image][key] = val\n",
    "        row['filepath'] = _ensure_str(filepath)\n",
    "        row['agnostic_path'] = path_to_agnostic(filepath)\n",
    "        seq_id = _ensure_str(h5_file.attrs['sequence_id'])\n",
    "        row['sequence'] = asdatetime(seq_id.split('_')[0])\n",
    "        try:\n",
    "            row['sequence_index'] = h5_file.attrs['sequence_index']\n",
    "        except KeyError:\n",
    "            row['sequence_index'] = None\n",
    "        if 'script' in h5_file: \n",
    "            row['labscript'] = _ensure_str(h5_file['script'].attrs['name'])\n",
    "        try:\n",
    "            row['run time'] = asdatetime(_ensure_str(h5_file.attrs['run time']))\n",
    "        except KeyError:\n",
    "            row['run time'] = float('nan')\n",
    "        try:    \n",
    "            row['run number'] = h5_file.attrs['run number']\n",
    "        except KeyError:\n",
    "            row['run number'] = float('nan')\n",
    "        try:\n",
    "            row['run repeat'] = h5_file.attrs['run repeat']\n",
    "        except KeyError:\n",
    "            row['run repeat'] = 0\n",
    "        return row\n",
    "            \n",
    "def flatten_dict(dictionary, keys=tuple()):\n",
    "    \"\"\"Takes a nested dictionary whose keys are strings, and returns a\n",
    "    flat dictionary whose keys are tuples of strings, each element of\n",
    "    which is the key for one level of the hierarchy.\"\"\"\n",
    "    result = {}\n",
    "    for name in dictionary:\n",
    "        if isinstance(dictionary[name],dict):\n",
    "            flat = flatten_dict(dictionary[name],keys=keys + (name,))\n",
    "            result.update(flat)\n",
    "        else:\n",
    "            result[keys + (name,)] = dictionary[name]\n",
    "    return result\n",
    "            \n",
    "def flat_dict_to_hierarchical_dataframe(dictionary):\n",
    "    \"\"\"Make all the keys tuples of the same length\"\"\"\n",
    "    max_tuple_length = 2 # Must have at least two levels to make a MultiIndex\n",
    "    for key in dictionary:\n",
    "        max_tuple_length = max(max_tuple_length,len(key))\n",
    "    result = {}\n",
    "    for key in dictionary:\n",
    "        newkey = key[:]\n",
    "        while len(newkey) < max_tuple_length:\n",
    "            newkey += ('',)\n",
    "        result[newkey] = dictionary[key]    \n",
    "    index = pandas.MultiIndex.from_tuples(sorted(result.keys()))\n",
    "    return pandas.DataFrame([result],columns=index)  \n",
    "\n",
    "def flat_dict_to_flat_series(dictionary):\n",
    "    result = {}\n",
    "    for key in dictionary:\n",
    "        if len(key) > 1:\n",
    "            result[key] = dictionary[key]\n",
    "        else:\n",
    "            result[key[0]] = dictionary[key]\n",
    "    keys = list(result.keys())\n",
    "    keys.sort(key = lambda item: \n",
    "        (len(item),) + item if isinstance(item, tuple) else (1,item))\n",
    "    return pandas.Series(result,index=keys)  \n",
    "          \n",
    "def get_dataframe_from_shot(filepath):\n",
    "    nested_dict = get_nested_dict_from_shot(filepath)\n",
    "    flat_dict =  flatten_dict(nested_dict)\n",
    "    df = flat_dict_to_hierarchical_dataframe(flat_dict)\n",
    "    return df\n",
    "    \n",
    "def get_dataframe_from_shots(filepaths):\n",
    "    return concat_with_padding(*[get_dataframe_from_shot(filepath) for filepath in filepaths])\n",
    "\n",
    "def get_series_from_shot(filepath):\n",
    "    nested_dict = get_nested_dict_from_shot(filepath)\n",
    "    flat_dict =  flatten_dict(nested_dict)\n",
    "    s = flat_dict_to_flat_series(flat_dict)\n",
    "    return s\n",
    "    \n",
    "def pad_columns(df, n):\n",
    "    \"\"\"Add depth to hiererchical column labels with empty strings\"\"\"\n",
    "    if df.columns.nlevels == n:\n",
    "        return df\n",
    "    new_columns = []\n",
    "    data = {}\n",
    "    for column in df.columns:\n",
    "        new_column = column + ('',)*(n-len(column))\n",
    "        new_columns.append(new_column)\n",
    "        data[new_column] = df[column]\n",
    "    index = pandas.MultiIndex.from_tuples(new_columns)\n",
    "    return pandas.DataFrame(data,columns = index)\n",
    "\n",
    "def concat_with_padding(*dataframes):\n",
    "    \"\"\"Concatenates dataframes with MultiIndex column labels,\n",
    "    padding shallower hierarchies such that the MultiIndexes have\n",
    "    the same nlevels.\"\"\"\n",
    "    dataframes = list(dataframes)\n",
    "    max_nlevels = max(df.columns.nlevels for df in dataframes)\n",
    "    # Remove empty dataframes (these don't concat since pandas 0.18) \n",
    "    dataframes = [df for df in dataframes if not df.empty]\n",
    "    for i, df in enumerate(dataframes):\n",
    "        if df.columns.nlevels < max_nlevels:\n",
    "            dataframes[i] = pad_columns(df, max_nlevels)\n",
    "    return pandas.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "def replace_with_padding(df, row, index):\n",
    "    if df.columns.nlevels < row.columns.nlevels:\n",
    "        df = pad_columns(df, row.columns.nlevels)\n",
    "    elif df.columns.nlevels > row.columns.nlevels:\n",
    "        row = pad_columns(row, df.columns.nlevels)\n",
    "\n",
    "    # Change the index of the row object to equal that of where it is to be\n",
    "    # inserted:\n",
    "    row.index = pandas.Int64Index([index])\n",
    "\n",
    "    # Replace the target row in the dataframe by dropping, appending, then\n",
    "    # sorting by index:\n",
    "    df = df.drop([index])\n",
    "    df = df.append(row)\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
